---
title: 智能实体在网络空间自动化防御系统中的应用
date: 2023-11-13 15:07:36
categories:
- Theories
- AI
tags:
- NLP
- IA
- GenAI
---

## 引言

自动化防御作为网络安全防御的发展趋势，一直是研究和讨论的重点话题。关于人工智能如何在其中发挥作用，尤其是目前大语言模型带来的变革，使得这一领域的热度空前高涨。

<!-- more -->

## 研究背景

目前的网络安全面临的主要问题有：
- 攻击技术日趋复杂：随着网络技术的不断发展，攻击者在攻击技术方面也不断创新，采用了更加复杂、隐蔽的攻击手段，传统的安全防护措施难以有效应对。
- 攻击目标日益扩大：随着网络技术的普及应用，网络空间已经成为人们工作、生活的重要场所，各种重要信息和系统都存储在网络空间中。攻击者不仅针对政府、企业等重要机构，也针对个人、家庭等普通用户发起攻击，攻击目标日益扩大。
- 攻击动机多样：攻击者的动机也越来越多样化，不仅有窃取数据、破坏系统等传统动机，还有破坏社会秩序、影响国家安全等动机。这也给网络安全防护带来了更大的挑战。
- 安全人才短缺：网络安全人才是网络安全防护的重要力量。随着网络安全形势日趋严峻，对网络安全人才的需求也越来越大。然而，目前我国网络安全人才短缺的现状依然存在。

面对以上四个主要问题，AI技术具有巨大的潜力，可以有效应对上述挑战，
- 针对攻击技术日趋复杂的挑战：
    - AI可以利用大数据分析技术，从海量数据中发现潜在的威胁，并对威胁进行深入分析，识别其攻击意图和行为模式，提高威胁检测和分析能力。
    - AI可以用于开发新的安全防护技术，相较于传统规则检测技术有着更好的泛化能力，从而更加有效地防御复杂、隐蔽的攻击。
- 针对攻击目标日益扩大的挑战：
    - AI可以用于自动化执行安全防护任务，例如漏洞扫描、威胁情报分析等，从而减轻安全人员的工作负担，提高安全防护的效率。
    - AI可以根据不同目标的特点，制定针对性的安全防护措施，从而提高安全防护的效果。
- 针对攻击动机多样化的挑战：
    - AI可以用于综合运用多种安全防护措施，从而提高安全防护的综合效果。
    - AI可以根据攻击动机的变化，调整安全防护措施，从而提高安全防护的灵活性。
- 针对安全人才短缺的挑战：
    - AI可以用于辅助安全人员执行安全防护任务，从而提高安全人员的工作效率。
    - AI可以用于自动化执行安全防护任务，从而减轻安全人员的工作负担。

总体而言，AI具有强大的学习和分析能力，可以有效应对网络安全面临的各种挑战，为提高网络安全水平提供新的思路和途径。

## 一些概念

人工智能（Artificial Intelligence）或者说 AI 是一个耳熟能详的名词。人工智能的潜在目标或定义包含以下四个方面：
- 思维模仿（Thinking Humanly）：通过人工智能技术使计算机系统能够模仿人类思维模式，包括推理、学习、问题解决等方面。
- 行为模仿（Acting Humanly）：使计算机系统能够表现出类似人类行为的特征，如语言交流、感知环境、执行任务等，以实现与人类的自然交互。
- 理性思考（Thinking Rationally）：通过逻辑推理、推断和问题求解等技术，使计算机能够以理性的方式思考和决策，而不仅仅是模仿人类的行为。
- 理性行为（Acting Rationally）：使计算机系统能够基于逻辑推理和准则行动，以实现在特定环境下最优化的决策和行为，而不一定模仿人类的行为方式。

另一个概念叫做 Intelligence Agent，简称 IA，直译为智能代理或者智能实体。早在 18，19 世纪，哲学家 Denis Diderot 就提出了类似的概念，“如果找到一只能够回答所有事情的鹦鹉，那我毫不犹豫的称它是一个智能体。“事实上，关于 Agent 的概念，其根源可追溯到亚里士多德和休谟等有影响力的思想家。从一般意义上讲，Agent 是指具有行动能力的实体，Agent 的概念涉及自主性，有着行使意志、做出选择和采取行动的能力，而不是被动地对外部刺激做出反应。在人工智能领域，Agent 是一种计算实体。从本质上讲，AI Agent 并不等同于哲学上的 Agent；相反，它是 Agent 这一哲学概念在人工智能领域的具体化。我们将 AI Agent 视为能够使用传感器感知周围环境，做出决策，然后使用执行器采取行动的人造实体。

IA 的发展趋势大致如下：
- 从最开始的符号式 Agents，典型代表为基于知识库的专家系统；
- 接着是反应式 Agents，根据环境的变化作出相应行动；
- 然后是如 AlphaGo 一般基于强化学习技术的 Agents；
- 再下面是结合了迁移学习和元学习技术的 Agents；
- 大语言模型横空出世之后，目前基于大语言模型的 Agents 成为全新的研究方向。

## 整体架构

为此我们提出基于GDDRR模型的智能防御体系，主要理念是在实战中实现治理、检测、决策、响应、恢复五项任务的快速高效循环。在智能 Agents 驱动下的智能防御体系概述如下：
- 为了实现系统高效运行，基于 Stix 2.1 框架，我们设计了一套完整的安全数据表示框架。在治理阶段，如威胁情报、资产台账、安全运营数据等均转换到统一的数据表示框架中去。通过知识图谱技术，存储到图数据库中，便于建立和展示数据实体间的相互关系。该阶段可参与的 Agents 类型包括符号式 Agents，反应式 Agents 以及大语言模型 Agents。
- 在检测阶段，符号式 Agents，具有迁移学习和元学习功能的 Agents 以及基于大语言模型的 Agents 通过学习人类安全专家的思维行为范式，在传统的基于机器学习、深度学习的检测小模型以及基于 pattern 匹配的规则引擎辅助下，快速高效的实现单步攻击识别。并在接下来的决策阶段，通过上下文的关联分析，将多种单步攻击串联，以攻击链的形式识别复合攻击，生成安全事件。
- 在响应和恢复阶段，反应式 Agents，基于强化学习技术的 Agents，联合迁移学习和元学习 Agents和大语言模型 Agents，根据单步攻击和复合攻击的研判结果，与对应安全产品交互，执行攻击阻断和风险修复的动作。
- 接下来又开始新一轮的循环，在全新的治理阶段中，更新上一轮循环提炼出的资产信息变更、运营数据变更以及攻防技战法等数据。循环往复，实现自洽的智能防御体系。

## 具体结构

以大语言模型 Agents 为例，我们认为 IA 可分为 3 个模块，脑模块，感知模块和行动模块。

### 脑模块

脑模块作为 IA 的中央处理核心，它的首要功能是自然语言交互功能，其中涉及到核心问题有：
- 多轮交互下的信息有效性和统一性问题；
- 高质量自然语言生成问题；
- 语言中隐藏含义的理解问题等。

第二个功能涉及到知识领域，每个 IA 需要了解对应的知识，大体上可分为 3 种：
- 语言知识，意味着 IA 需要了解输入的统一数据表示的意义；
- 常识知识；
- 专业领域知识。

第三个是记忆功能，如何保证多轮交互以及多 Agent 交互之后的信息同步是很重要的课题。为此可能的解决办法有：
- 提升 transformer 模型的长度限制；
- 将信息抽象提炼，再存入记忆模块；
- 压缩信息，寻找更为高效的信息表示方法；
- 共享记忆，类似外挂知识库的方案，但是这种做法又会涉及到数据隐私和安全的问题，我们后面再讨论。

第四个是推理和规划功能，旨在培养 IA 形成人类一样的链式思维，一步一步的进行推导和规划。

最后是学习功能，为了形成自洽的系统，IA 必须要自主学习，从而摆脱必须依赖人类指令运行的情况。

### 感知模块

第二个是感知模块，这个模块相对而言比较简单明了，就是将多源异构的数据转换成统一的数据表示。

### 行为模块

最后一个是行为模块，这也是 IA 相对比较重要的模块。主要分为 2 个子功能：
- 第一个是文字输出功能，即将抽象的统一数据转换成人类理解的自然语言。
- 第二个是工具模块。这里主要考虑的是在响应和恢复阶段，IA 需要能够根据分析研判结果，调用甚至制造对应的工具实现攻击阻断和风险修复等工作任务。

### 信息交互

介绍完 Agent 架构之后，下面简要介绍一下系统内信息交互的模式。

首先对于单个 Agent 来说，主要分为3种情况：
- 第一种是任务导向，那么这个 IA 只需要接受输入，根据人类指定的行为范式给出输出；
- 第二种是灵感导向，意思是人类给出一个目标，IA从结果逆推，自行寻找需要的输入并完成目标；
- 第三种是生命周期导向，是指类似 AutoGPT 那样的实体，自身实现一个任务的闭环运行无需人类的指令。

对于 Agents 之间的交互场景概括起来其实很简单，就分为两种情况：
- 一是多个 Agents 合作完成任务的模式；
- 二是 Agents 之间通过对抗的模式相互促进。

最后是人机交互，也分为两种情况：
- 一是指导-执行范式。指人类给出指令，指导 IA 执行对应动作；
- 二是合作范式，指人咧和机器合作完成相应任务目标。

## 困难与挑战

理论框架介绍完成之后，接下来是面临的一些困难和挑战：
- 首先是数据隐私和安全问题。目前以及未来都面临着 Agent 即服务的情况，指的是 Agent 就是人机交互的接口。IA 需要接触大量的数据去完成对应的任务，与之交互的人也就等于变相的接触到了这些数据。如何在这个环节中做好隐私数据防泄露，数据访问控制等问题至关重要。
- 第二个问题是，AI 模型本身因为数据集不平衡，算法不公平等客观条件的制约，存在定型观念和偏见。如何在多 Agents 交互的系统中始终保证平衡，不因为害群之马导致整个系统偏离方向也是个挑战。
- 为此，针对这样一个自洽的系统，需要一套行之有效的评估系统和约束手段，包含但不限于数据治理、算法治理、系统治理和伦理治理等方面。

除了上面提到的困难与挑战，其实还有两点疑思值得进一步研究：
- 首先是可信度问题。当人过于依赖智能的时候，保证结果的高置信度就是极大的考验，一些简单的小模型能够做到这一点，但是上升到庞大的系统可能需要全新的机制来保障。
- 其次是可靠性问题。对抗训练是目前机器学习领域热门的话题，即如何保证模型的鲁棒性，使其即使在受到特定攻击的情况下依然能够给出正确的判别结果。

## 总结

以大语言模型为代表的 AI 技术给未来的体系架构带来了无限的可能，当然其中也暗藏着种种问题。当然我们应该对 AI 技术保持信心，毕竟它已经实现了许多人类之前难以想象的功能。未来的研究方向将聚焦于智能 Agent 的新方向，以及人工智能技术与网络安全自动化防御的更多结合。
